---
title: "ME114 Lab 8: Unsupervised learning and dimensional reduction"
author: "Ken Benoit and Slava Mikhaylov"
output: html_document
bibliography: ../bibliography/bibliography.bib
---


This lab session is based on lab exercises in @james2013 [Chapter 10.1-10.2].


## Lab 1: Principal Components Analysis

We use the [`USArrests`](http://bit.ly/R_us_arrests) dataset in this exercise to run Principal Component Analysis (PCA). We start by examining the data with some descriptive statistics.

```{r}
states <- row.names(USArrests)
states
```

```{r}
names(USArrests)
```

Let's check the mean and variance of the `USArrests` dataset.

```{r}
apply(USArrests, 2, mean)
```

```{r}
apply(USArrests, 2, var)
```

We run PCA on our dataset using the [`prcomp()`](http://bit.ly/R_prcomp) function.

```{r}
pr.out <- prcomp(USArrests, scale = TRUE)
```

Now let's examine the results from the [`prcomp()`](http://bit.ly/R_prcomp) function.

```{r}
names(pr.out)
```

The `center` and `scale` components contain the mean and standard deviations prior to scaling.

```{r}
pr.out$center
pr.out$scale
```

The `rotation` component corresponds to the rotation matrix whose columns contain the eigenvectors.

```{r}
pr.out$rotation
```

Let's check the dimensions of `x` component which returns the rotated data.

```{r}
dim(pr.out$x)
```

We then plot the first two principal components using [`biplot()`](http://bit.ly/R_biplot).

```{r}
biplot(pr.out, scale = 0)
```

```{r}
pr.out$rotation <- -pr.out$rotation
pr.out$x <- -pr.out$x
biplot(pr.out, scale = 0)
```

We can compute the variance associated with each principal component from the standard deviation returned by [`prcomp()`](http://bit.ly/R_prcomp).

```{r}
pr.out$sdev
```

```{r}
pr.var <- pr.out$sdev^2
pr.var
```

Let's compute the proportional variance as well.

```{r}
pve <- pr.var/sum(pr.var)
pve
```

Now we can plot the proportional variance for each principal component.

```{r}
plot(pve, xlab = "Principal Component", ylab = "Proportion of Variance Explained ", ylim = c(0, 1), type = "b")
plot(cumsum(pve), xlab = "Principal Component ", ylab = " Cumulative Proportion of Variance Explained ", ylim = c(0, 1), type = "b")
```

```{r}
a <- c(1, 2, 8, -3)
cumsum(a)
```



## Lab 2: NCI60 Data Example

In this exercise, we apply PCA to the gene expression dataset from the Stanford NC160 Cancer Microarray Project.

```{r}
library(ISLR)
nci.labs <- NCI60$labs
nci.data <- NCI60$data
```

Let's examine the dimensions of the dataset.

```{r}
dim(nci.data)
```

The [`table()`](http://bit.ly/R_table) function can be used to produce crosstabs from the dataset.

```{r}
nci.labs[1:4]
table(nci.labs)
```

### PCA on the NCI60 Data

We use [`prcomp()`](http://bit.ly/R_prcomp) to run principal component analysis as shown in the PCA exercise above.

```{r}
pr.out <- prcomp(nci.data, scale = TRUE)
```

We create a function to assign unique colors to each cancer type.

```{r}
Cols <- function(vec) {
    cols <- rainbow(length(unique(vec)))
    return(cols[as.numeric(as.factor(vec))])
}
```

We can now use our `Cols()` function to plot the PCA results.

```{r}
par(mfrow = c(1, 2))
plot(pr.out$x[, 1:2], col = Cols(nci.labs), pch = 19, xlab = "Z1", ylab = "Z2")
plot(pr.out$x[, c(1, 3)], col = Cols(nci.labs), pch = 19, xlab = "Z1", ylab = "Z3")
```

We can get a summary of the proportional variance and plot the variance explained by each principal component.

```{r}
summary(pr.out)
plot(pr.out)
```

We can also plot the proportional variance explained (PVE) and the cumulative PVE for each principal component.

```{r}
pve <- 100 * pr.out$sdev^2/sum(pr.out$sdev^2)
par(mfrow = c(1, 2))
plot(pve, type = "o", ylab = "PVE", xlab = "Principal Component", col = " blue ")
plot(cumsum(pve), type = "o", ylab = "Cumulative PVE", xlab = "Principal Component ", col = " brown3 ")
```


## References
